{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import opacus\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import easydict\n",
    "from prv_accountant.dpsgd import find_noise_multiplier\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from opacus.utils.batch_memory_manager import wrap_data_loader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda:0\"\n",
    "DATASET_TO_CLASSES = {'CIFAR10': 10,\n",
    "            'CIFAR100': 100,\n",
    "            'FashionMNIST': 10,\n",
    "            'STL10': 10}\n",
    "ARCH_TO_INTERP_SIZE = {\"beit_large_patch16_512\": 512,\n",
    "        \"convnext_xlarge_384_in22ft1k\": 384,\n",
    "        \"beitv2_large_patch16_224_in22k\": 224}\n",
    "args = easydict.EasyDict({\"dataset\":  \"STL10\",\n",
    "    \"arch\":     \"beit_large_patch16_512\",\n",
    "    \"lr\":       0.01,\n",
    "    \"epochs\":   1,\n",
    "    \"epsilon\":  0.1,\n",
    "    \"dataset_path\":  \"datasets/\"})\n",
    "args.sigma = find_noise_multiplier(sampling_probability=1.0,\n",
    "    num_steps=args.epochs,\n",
    "    target_epsilon=args.epsilon,\n",
    "    target_delta=1e-5,\n",
    "    eps_error=0.001,\n",
    "    mu_max=5000)\n",
    "args.num_classes = DATASET_TO_CLASSES[args.dataset]\n",
    "\n",
    "def get_features(f, images, interp_size=224, batch=64):\n",
    "    features = []\n",
    "    for img in tqdm(images.split(batch)):\n",
    "        with torch.no_grad():\n",
    "            img = F.interpolate(img.cuda(), size=(interp_size, interp_size), mode=\"bicubic\")\n",
    "            features.append(f(img).detach().cpu())\n",
    "    return torch.cat(features)\n",
    "\n",
    "def get_ds(args):\n",
    "    if args.dataset == \"STL10\":\n",
    "        ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), split='train', download=True)\n",
    "        images_train, labels_train = torch.tensor(ds.data) / 255.0, torch.tensor(ds.labels)\n",
    "        ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), split='test', download=True)\n",
    "        images_test, labels_test = torch.tensor(ds.data) / 255.0, torch.tensor(ds.labels)\n",
    "    elif args.dataset == \"FashionMNIST\":\n",
    "        ds_train = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=True, download=True)\n",
    "        ds_test = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=False, download=True)\n",
    "        images_train, labels_train = torch.tensor(ds_train.data.unsqueeze(1).repeat(1, 3, 1, 1)).float() / 255.0, torch.tensor(ds_train.targets)\n",
    "        images_test, labels_test = torch.tensor(ds_test.data.unsqueeze(1).repeat(1, 3, 1, 1)).float() / 255.0, torch.tensor(ds_test.targets)\n",
    "    else:\n",
    "        ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=True, download=True)\n",
    "        images_train, labels_train = torch.tensor(ds.data.transpose(0, 3, 1, 2)) / 255.0, torch.tensor(ds.targets)\n",
    "        ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=False, download=True)\n",
    "        images_test, labels_test = torch.tensor(ds.data.transpose(0, 3, 1, 2)) / 255.0, torch.tensor(ds.targets)\n",
    "    feature_extractor = nn.DataParallel(timm.create_model(args.arch, num_classes=0, pretrained=True)).eval().cuda()    \n",
    "    features_train = get_features(feature_extractor, images_train, interp_size=ARCH_TO_INTERP_SIZE[args.arch])\n",
    "    features_test = get_features(feature_extractor, images_test, interp_size=ARCH_TO_INTERP_SIZE[args.arch])\n",
    "    ds_train = TensorDataset(features_train, labels_train)\n",
    "    args.batch_size = len(ds_train)\n",
    "    train_loader = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True, **{'num_workers': 4, 'pin_memory': True})\n",
    "    ds_test = TensorDataset(features_test, labels_test)\n",
    "    test_loader = DataLoader(ds_test, batch_size=len(ds_test), shuffle=False, **{'num_workers': 4, 'pin_memory': True})\n",
    "    return train_loader, test_loader, features_test.shape[-1], len(labels_test)\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        criterion(model(data), target).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, test_loader):\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            model.eval()\n",
    "            pred = model(data).argmax(dim=1, keepdim=True)\n",
    "            acc += pred.eq(target.view_as(pred)).sum().item() * 100/len_test\n",
    "    return acc\n",
    "\n",
    "train_loader, test_loader, num_features, len_test = get_ds(args)\n",
    "model = nn.Linear(num_features, args.num_classes, bias=False).cuda()\n",
    "model.weight.data.zero_()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "privacy_engine = opacus.PrivacyEngine(accountant=\"gdp\")\n",
    "model, optimizer, train_loader = privacy_engine.make_private(module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=args.sigma,\n",
    "    max_grad_norm=1)\n",
    "train_loader = wrap_data_loader(data_loader=train_loader, max_batch_size=5000, optimizer=optimizer)\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    print(f\"Epoch {epoch} Test Accuracy {test(model, test_loader):.2f}\")   \n",
    "print(f\"Epsilon {privacy_engine.accountant.get_epsilon(delta=1e-5):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
