{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b4ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import opacus\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import easydict\n",
    "from prv_accountant.dpsgd import find_noise_multiplier\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from opacus.utils.batch_memory_manager import wrap_data_loader\n",
    "import torch_scatter\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda:0\"\n",
    "DATASET_TO_CLASSES = {'CIFAR10': 10,\n",
    "            'CIFAR100': 100,\n",
    "            'FashionMNIST': 10,\n",
    "            'STL10': 10,\n",
    "            'waterbirds': 2,\n",
    "            'fmow': 62,\n",
    "            'camelyon17': 2}\n",
    "ARCH_TO_INTERP_SIZE = {\"beit_large_patch16_512\": 512,\n",
    "        \"convnext_xlarge_384_in22ft1k\": 384,\n",
    "        \"beitv2_large_patch16_224_in22k\": 224}\n",
    "args = easydict.EasyDict({\"dataset\":  \"waterbirds\",\n",
    "    \"arch\":     \"beitv2_large_patch16_224_in22k\",\n",
    "    \"lr\":       1,\n",
    "    \"epochs\":   1,\n",
    "    \"epsilon\":  0.01,\n",
    "    \"dataset_path\":  \"/data/nvme/ashwinee/datasets/\"})\n",
    "args.num_classes = DATASET_TO_CLASSES[args.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b20aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_features(f, images, interp_size=224, batch=64):\n",
    "#     features = []\n",
    "#     for img in tqdm(images.split(batch)):\n",
    "#         with torch.no_grad():\n",
    "#             img = F.interpolate(img.cuda(), size=(interp_size, interp_size), mode=\"bicubic\")\n",
    "#             features.append(f(img).detach().cpu())\n",
    "#     return torch.cat(features)\n",
    "\n",
    "# def get_ds(args):\n",
    "#     if args.dataset == \"STL10\":\n",
    "#         ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), split='train', download=True)\n",
    "#         images_train, labels_train = torch.tensor(ds.data) / 255.0, torch.tensor(ds.labels)\n",
    "#         ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), split='test', download=True)\n",
    "#         images_test, labels_test = torch.tensor(ds.data) / 255.0, torch.tensor(ds.labels)\n",
    "#     elif args.dataset == \"FashionMNIST\":\n",
    "#         ds_train = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=True, download=True)\n",
    "#         ds_test = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=False, download=True)\n",
    "#         images_train, labels_train = torch.tensor(ds_train.data.unsqueeze(1).repeat(1, 3, 1, 1)).float() / 255.0, torch.tensor(ds_train.targets)\n",
    "#         images_test, labels_test = torch.tensor(ds_test.data.unsqueeze(1).repeat(1, 3, 1, 1)).float() / 255.0, torch.tensor(ds_test.targets)\n",
    "#     else:\n",
    "#         ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=True, download=True)\n",
    "#         images_train, labels_train = torch.tensor(ds.data.transpose(0, 3, 1, 2)) / 255.0, torch.tensor(ds.targets)\n",
    "#         ds = getattr(datasets, args.dataset)(args.dataset_path, transform=transforms.ToTensor(), train=False, download=True)\n",
    "#         images_test, labels_test = torch.tensor(ds.data.transpose(0, 3, 1, 2)) / 255.0, torch.tensor(ds.targets)\n",
    "#     feature_extractor = nn.DataParallel(timm.create_model(args.arch, num_classes=0, pretrained=True)).eval().cuda()    \n",
    "#     features_train = get_features(feature_extractor, images_train, interp_size=ARCH_TO_INTERP_SIZE[args.arch])\n",
    "#     features_test = get_features(feature_extractor, images_test, interp_size=ARCH_TO_INTERP_SIZE[args.arch])\n",
    "#     ds_train = TensorDataset(features_train, labels_train)\n",
    "#     args.batch_size = len(ds_train)\n",
    "#     train_loader = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True, **{'num_workers': 4, 'pin_memory': True})\n",
    "#     ds_test = TensorDataset(features_test, labels_test)\n",
    "#     test_loader = DataLoader(ds_test, batch_size=len(ds_test), shuffle=False, **{'num_workers': 4, 'pin_memory': True})\n",
    "#     return train_loader, test_loader, features_test.shape[-1], len(labels_test)\n",
    "\n",
    "# def train(model, train_loader, optimizer):\n",
    "#     model.train()\n",
    "#     for data, target in tqdm(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad() \n",
    "#         criterion(model(data), target).backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# def test(model, test_loader):\n",
    "#     acc = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in tqdm(test_loader):\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             model.eval()\n",
    "#             pred = model(data).argmax(dim=1, keepdim=True)\n",
    "#             acc += pred.eq(target.view_as(pred)).sum().item() * 100/len_test\n",
    "#     return acc\n",
    "\n",
    "# train_loader, test_loader, num_features, len_test = get_ds(args)\n",
    "# model = nn.Linear(num_features, args.num_classes, bias=False).cuda()\n",
    "# model.weight.data.zero_()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "# privacy_engine = opacus.PrivacyEngine(accountant=\"gdp\")\n",
    "# model, optimizer, train_loader = privacy_engine.make_private(module=model,\n",
    "#     optimizer=optimizer,\n",
    "#     data_loader=train_loader,\n",
    "#     noise_multiplier=args.sigma,\n",
    "#     max_grad_norm=1)\n",
    "# train_loader = wrap_data_loader(data_loader=train_loader, max_batch_size=5000, optimizer=optimizer)\n",
    "# for epoch in range(1, args.epochs + 1):\n",
    "#     train(model, train_loader, optimizer)\n",
    "#     print(f\"Epoch {epoch} Test Accuracy {test(model, test_loader):.2f}\")   \n",
    "# print(f\"Epsilon {privacy_engine.accountant.get_epsilon(delta=1e-5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6dde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_wilds_ds(dataset_name, \n",
    "                  root_dir=\"/data/nvme/ashwinee/datasets\"):\n",
    "    # Load the full dataset, and download it if necessary\n",
    "    dataset = get_dataset(dataset=dataset_name, download=True, root_dir=root_dir)\n",
    "\n",
    "    # Get the training set\n",
    "    train_data = dataset.get_subset(\n",
    "        \"train\",\n",
    "        transform=transforms.Compose(\n",
    "        [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    "    ),\n",
    "    )\n",
    "\n",
    "    # Prepare the standard data loader\n",
    "    train_loader = get_train_loader(\"standard\", train_data, batch_size=64)\n",
    "    \n",
    "    # Get the training set\n",
    "    test_data = dataset.get_subset(\n",
    "        \"test\",\n",
    "        transform=transforms.Compose(\n",
    "        [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    "    ),\n",
    "    )\n",
    "\n",
    "    # Prepare the standard data loader\n",
    "    test_loader = get_eval_loader(\"standard\", test_data, batch_size=6400)\n",
    "    return train_data, test_data, train_loader, test_loader, dataset\n",
    "\n",
    "def gen_wilds_ds(train_loader, test_loader, arch=\"beitv2_large_patch16_224_in22k\"):\n",
    "    feature_extractor = nn.DataParallel(timm.create_model(arch, num_classes=0, pretrained=True)).eval().cuda()\n",
    "    \n",
    "    def get_features(f, imgs, interp_size):\n",
    "        features = []\n",
    "        for batch in tqdm(imgs):\n",
    "            img = batch[0]\n",
    "            img = F.interpolate(img.cuda(), size=(interp_size, interp_size), mode=\"bicubic\")\n",
    "            features.append(feature_extractor(img).detach().cpu())\n",
    "        return torch.cat(features)\n",
    "    \n",
    "    interp_size = ARCH_TO_INTERP_SIZE[arch]\n",
    "    features_train = get_features(feature_extractor, train_loader, interp_size=interp_size)\n",
    "    features_test = get_features(feature_extractor, test_loader, interp_size=interp_size)\n",
    "    return features_train, features_test\n",
    "    \n",
    "def get_wilds_ds(args):\n",
    "    ### GET DATA\n",
    "    dataset_path = args.dataset_path + args.dataset\n",
    "    # we need to keep around the original test_loader so that we can use the eval function\n",
    "    train_data, test_data, train_loader, eval_loader, dataset = load_wilds_ds(args.dataset, root_dir=args.dataset_path)\n",
    "    labels_train, labels_test = train_data.y_array, test_data.y_array\n",
    "    ### GET PATH\n",
    "    abbrev_arch = args.arch\n",
    "    extracted_path = args.dataset_path + \"transfer/features/\" + args.dataset.lower() + \"_\" + abbrev_arch\n",
    "    extracted_train_path = extracted_path + \"/_train.npy\"\n",
    "    extracted_test_path = extracted_path + \"/_test.npy\"\n",
    "    if not os.path.exists(extracted_path):\n",
    "        features_train, features_test = gen_wilds_ds(train_loader,\n",
    "                                                     test_loader,\n",
    "                                                 args.arch)\n",
    "        os.makedirs(extracted_path, exist_ok=True)\n",
    "        np.save(extracted_train_path, features_train)\n",
    "        np.save(extracted_test_path, features_test)  \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    x_train = np.load(extracted_train_path)\n",
    "    features_train = torch.from_numpy(x_train)\n",
    "    ds_train = TensorDataset(features_train, labels_train)\n",
    "    args.batch_size = len(ds_train)\n",
    "    train_loader = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    x_test = np.load(extracted_test_path)\n",
    "    features_test = torch.from_numpy(x_test)\n",
    "    ds_test = TensorDataset(features_test, labels_test)\n",
    "    test_loader = DataLoader(ds_test, batch_size=len(ds_test), shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader, features_test.shape[-1], len(labels_test), dataset, eval_loader, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7391162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_all(args):\n",
    "    train_loader, test_loader, num_features, len_test, dataset, eval_loader, test_data = get_wilds_ds(args)\n",
    "    model = nn.Linear(num_features, args.num_classes, bias=False).cuda()\n",
    "    model.weight.data.zero_()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False)\n",
    "    privacy_engine = None\n",
    "    if args.do_dp:\n",
    "        args.sigma = find_noise_multiplier(sampling_probability=1.0,\n",
    "            num_steps=args.epochs,\n",
    "            target_epsilon=args.epsilon,\n",
    "            target_delta=1e-5,\n",
    "            eps_error=0.1,\n",
    "            mu_max=5000)\n",
    "        privacy_engine = opacus.PrivacyEngine(secure_mode=False, accountant=\"gdp\")\n",
    "        model, optimizer, train_loader = privacy_engine.make_private(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier=args.sigma,\n",
    "            max_grad_norm=1,\n",
    "            clipping=\"flat\",\n",
    "            poisson_sampling=True,\n",
    "        )\n",
    "    return model, optimizer, privacy_engine, train_loader, test_loader, num_features, len_test, dataset, eval_loader, test_data\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(args, model, device, test_loader, dataset):\n",
    "    model.eval()\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_metadata = []\n",
    "\n",
    "    for data, y_true in test_loader:\n",
    "        data, y_true = data.to(device), y_true.to(device)\n",
    "        y_pred = model(data).argmax(dim=1, keepdim=True)\n",
    "        all_y_true.append(y_true.cpu())\n",
    "        all_y_pred.append(y_pred.cpu())\n",
    "\n",
    "    all_y_true = torch.cat(all_y_true)\n",
    "    all_y_pred = torch.cat(all_y_pred).squeeze()\n",
    "\n",
    "    all_metadata = test_data.metadata_array\n",
    "    results, results_str = dataset.eval(all_y_pred, all_y_true, all_metadata)\n",
    "    print(results_str)\n",
    "    return results\n",
    "\n",
    "def do_everything(args):\n",
    "    model, optimizer, privacy_engine, train_loader, test_loader, num_features, len_test, dataset, eval_loader, test_data = setup_all(args)\n",
    "    for i in range(args.epochs):\n",
    "        train(args, model, device, train_loader, optimizer)\n",
    "        test(args, model, device, test_loader, dataset)\n",
    "    if args.do_dp:\n",
    "        print(privacy_engine.accountant.get_epsilon(delta=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fff32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grads_weights(args):\n",
    "    \"\"\"\n",
    "    Load noisy grads, raw grads and weights from the checkpoint path corresponding to args\n",
    "    \"\"\"\n",
    "    noisy_grads, raw_grads, weights = None, None, None\n",
    "    loaded_arrays = np.load(f\"dp_finetuning/grad_datasets/{args.arch}/{args.dataset}/grads_weights_{args.num_runs}_{args.epochs}_{int(args.lr)}_{int(args.epsilon)}.npz\", allow_pickle=True)\n",
    "    noisy_grads = loaded_arrays[\"noisy_grads\"]\n",
    "    raw_grads = loaded_arrays[\"raw_grads\"]\n",
    "    weights = loaded_arrays[\"weights\"]\n",
    "    return noisy_grads, raw_grads, weights\n",
    "\n",
    "def set_weights(model, args):\n",
    "    \"\"\"\n",
    "    load the weights from the checkpoint path corresponding to args\n",
    "    set the weights to the model\n",
    "    \"\"\"\n",
    "    noisy_grads, raw_grads, weights = load_grads_weights(args)\n",
    "    final_weights = torch.from_numpy(weights[-1,-1])\n",
    "    final_weights = final_weights.to(args.device).view_as(model.weight.data)\n",
    "    model.weight.data.zero_()\n",
    "    model.weight.data.add_(final_weights)\n",
    "    return model\n",
    "\n",
    "from dp_finetuning.stl_cifar_style import STL10 as STL10_CIFAR\n",
    "from dp_finetuning.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "09f1c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.update({\n",
    "    \"lr\":       1,\n",
    "    \"epochs\":   110,\n",
    "    \"epsilon\":  0,\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    \"do_dp\": True,\n",
    "    \"num_runs\": 1,\n",
    "    \"workers\": 1,\n",
    "    \"augmult\": -1,\n",
    "    \"batch_size\": -1,\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"num_classes\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ef45b04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_grads, raw_grads, weights = load_grads_weights(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3e55a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=10, bias=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader, num_features, len_test = get_ds(args)\n",
    "model = nn.Linear(num_features, args.num_classes, bias=False).cuda()\n",
    "model = set_weights(model, args)\n",
    "# hardcode the model to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "339433fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "STL_CIFAR_dataset = STL10_CIFAR(\n",
    "            root = \"/data/nvme/ashwinee/datasets\",\n",
    "            split = \"test\",\n",
    "            folds = None,\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3801b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = args.dataset_path\n",
    "abbrev_arch = args.arch\n",
    "extracted_path = args.dataset_path + \"transfer/features/\" + args.dataset.lower() + \"_\" + abbrev_arch\n",
    "extracted_train_path = extracted_path + \"/_train.npy\"\n",
    "extracted_test_path = extracted_path + \"/_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ee11a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = torch.tensor(STL_CIFAR_dataset.data) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f86a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor(STL_CIFAR_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b42c3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = \"STL_CIFAR\"\n",
    "args.seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6d22faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING AND SAVING EXTRACTED FEATURES AT  /data/nvme/ashwinee/datasets/transfer/features/cifar10_beitv2_large_patch16_224_in22k/_train.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 113/113 [01:12<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "### GET DATA\n",
    "dataset_path = args.dataset_path + args.dataset\n",
    "\n",
    "### GET PATH\n",
    "abbrev_arch = args.arch\n",
    "extracted_path = args.dataset_path + \"transfer/features/\" + args.dataset.lower() + \"_\" + abbrev_arch\n",
    "extracted_test_path = extracted_path + \"/_test.npy\"\n",
    "\n",
    "### DO EXTRACTION\n",
    "\n",
    "print(\"GENERATING AND SAVING EXTRACTED FEATURES AT \", extracted_train_path)\n",
    "feature_extractor = nn.DataParallel(timm.create_model(args.arch, num_classes=0, pretrained=True)).eval().cuda()\n",
    "from collections import defaultdict\n",
    "ARCH_TO_INTERP_SIZE = defaultdict(lambda: 224)\n",
    "archs_to_interp_sizes = {\n",
    "    \"beit_large_patch16_512\": 512,\n",
    "    \"convnext_xlarge_384_in22ft1k\": 384,\n",
    "    \"vit_large_patch16_384\": 384,\n",
    "    \"vit_base_patch16_384\": 384,\n",
    "    \"tf_efficientnet_l2_ns\": 800,\n",
    "}\n",
    "ARCH_TO_INTERP_SIZE.update(archs_to_interp_sizes)\n",
    "interp_size = ARCH_TO_INTERP_SIZE[args.arch]\n",
    "features_test = get_features(feature_extractor, images_test, interp_size=interp_size)\n",
    "os.makedirs(extracted_path, exist_ok=True)\n",
    "np.save(extracted_test_path, features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3b3ef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(extracted_test_path)\n",
    "features_test = torch.from_numpy(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "43be0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = TensorDataset(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4dd10c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(ds_test, batch_size=len(ds_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "14312ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, test_loader):\n",
    "    device = args.device\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            corr = pred.eq(target.view_as(pred))\n",
    "            acc += corr.sum().item() * 100/target.shape[0]\n",
    "    print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "30e981c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.81944444444444"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(args, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b297cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
